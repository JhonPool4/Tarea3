{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 4\n",
    "\n",
    "Leer las imágenes de la carpeta `pregunta4` de forma similar a como se realizó en la pregunta 3. Notar que las imágenes son reales y su tamaño es variable: no se encuentran pre-procesadas. Por este motivo al importar es necesario escalar todas las imágenes al mismo tamaño, para poder tener una entrada uniforme a la red neuronal.\n",
    "\n",
    "Notar, además, que en este caso la carpeta `pregunta4` contiene 2 subcarpetas llamadas `train` y `validation`. Se debe cargar ambas carpetas por separado ya que cada una contiene datos diferentes, para el entrenamiento y la validación, respectivamente. Es decir, se debe utilizar dos `ImageDataGenerators`. Se sugiere utilizar un `batch_size` de 20.\n",
    "\n",
    "Debido a que en este caso hay un conjunto de entrenamiento y uno de validación, al momento de usar el método `fit_generator` del modelo, se debe adicionalmente pasar los parámetros `validation_data=datos_validation` y `validation_steps=50`, donde `datos_validation` contiene las imágenes del conjunto de validación. Igualmente, se debe recuperar lo que retorna la función `fit_generator` en una variable llamada `historia` tal que: `historia=modelo.fit_generator(...)`, donde los tres puntos son los parámetros que se pasa al método. \n",
    "\n",
    "Usar solamente 15 épocas. Debido a que no se cuenta con muchas imágenes para el entrenamiento, la exactitud no será muy alta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para compilar el modelo utilizar como optimizador RMSprop de la siguiente manera: optimizer=RMSprop(lr=0.001)\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la Exactitud del modelo \n",
    "\n",
    "Luego de entrenado el modelo, se debe correr el siguiente código para visualizar la evolución de la exactitud del modelo. A partir del análisis de los gráficos, indicar si existe overfitting.\n",
    "\n",
    "Notar que, debido a que no se cuenta con muchas imágenes para el entrenamiento, la exactitud no será muy alta.\n",
    "\n",
    "*Nota*: Según la versión de tensorflow, podría ser necesario reempazar 'accuracy' por 'acc', y 'val_accuracy' por 'val_acc'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolución de la exactitud y costo para el conjunto de entrenamiento y de validación, por época\n",
    "acc      = historia.history['accuracy']\n",
    "val_acc  = historia.history['val_accuracy']\n",
    "loss     = historia.history[    'loss']\n",
    "val_loss = historia.history['val_loss']\n",
    "\n",
    "# Número de épocas\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Gráfico de la exactitud para el entrenamiento y la validación\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Evolución de la exactitud')\n",
    "plt.figure()\n",
    "\n",
    "# Gráfico del costo para el entrenamiento y la validación\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Costo (loss) en entrenamiento y validación')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación del modelo\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Especificar la ruta a una imagen (completar con la ruta a la imagen)\n",
    "path = 'pregunta4/....jpg'\n",
    "\n",
    "# Cargar la imagen y escalarla a 300x300 (igual que las imágenes de entrenamiento)\n",
    "img = image.load_img(path, target_size=(150, 150))\n",
    "# Preprocesamiento\n",
    "X = image.img_to_array(img)\n",
    "X = np.expand_dims(X, axis=0)\n",
    "\n",
    "# Predicción\n",
    "clase = model.predict(X, batch_size=10)\n",
    "if (clase > 0.5):\n",
    "    print(\"Es un perro\")\n",
    "else:\n",
    "    print(\"Es un gato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento de los Parámetros Entrenados\n",
    "\n",
    "Por defecto, los pesos y la arquitectura se pueden almacenar en un archivo de tipo hdf5. Debido a la cantidad de pesos de la red, este archivo puede ser relativamente grande (en este caso aproximadamente 75 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALmacenar todo el modelo (pesos y arquitectura)\n",
    "model.save('pregunta4.h5')\n",
    "# Para más información ver: https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el modelo entrenado\n",
    "nuevo_modelo = tf.keras.models.load_model('pregunta4.h5')\n",
    "# Mostrar la arquitectura del modelo\n",
    "nuevo_modelo.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
